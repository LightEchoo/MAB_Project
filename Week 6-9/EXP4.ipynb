{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:44.784380Z",
     "start_time": "2024-08-11T05:58:43.020462Z"
    }
   },
   "id": "ef41e642e988e0bc",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.stats import norm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.134290Z",
     "start_time": "2024-08-11T05:58:44.788218Z"
    }
   },
   "id": "5eabe558929caa5f",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if not os.path.exists('image_4'):\n",
    "    os.makedirs('image_4')"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.138960Z",
     "start_time": "2024-08-11T05:58:46.135299Z"
    }
   },
   "id": "initial_id",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.181296Z",
     "start_time": "2024-08-11T05:58:46.139963Z"
    }
   },
   "id": "4c858c12d4e8bfe0",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.188204Z",
     "start_time": "2024-08-11T05:58:46.183300Z"
    }
   },
   "id": "c9973ddcc83532e3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # 检查 PyTorch 版本\n",
    "# print(\"PyTorch version:\", torch.__version__)\n",
    "# \n",
    "# # 检查 CUDA 可用性\n",
    "# print(\"CUDA available:\", torch.cuda.is_available())\n",
    "# \n",
    "# # 创建一个简单的张量并进行基本运算\n",
    "# a = torch.tensor([1.0, 2.0, 3.0])\n",
    "# b = torch.tensor([4.0, 5.0, 6.0])\n",
    "# print(\"a + b =\", a + b)\n",
    "# \n",
    "# # 测试其他函数是否正常工作\n",
    "# import numpy as np\n",
    "# \n",
    "# def test_function():\n",
    "#     print(\"This is a test function.\")\n",
    "# \n",
    "# test_function()\n",
    "# \n",
    "# print(\"NumPy version:\", np.__version__)\n",
    "# print(\"NumPy array:\", np.array([1, 2, 3]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.194193Z",
     "start_time": "2024-08-11T05:58:46.189207Z"
    }
   },
   "id": "43f90bfd02e1453a",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EXP4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "196beee7aaeb54e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# test_data = np.random.rand(10, 1000)\n",
    "# \n",
    "# # Plotting means_load\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(test_data, marker='o', linestyle='-', color='b', label='means_load')\n",
    "# plt.title('Random Means for Load')\n",
    "# plt.xlabel('Node')\n",
    "# plt.ylabel('Mean Load')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# \n",
    "# # Adjust layout\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.201422Z",
     "start_time": "2024-08-11T05:58:46.195203Z"
    }
   },
   "id": "f86f064ad92bf091",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to generate random means\n",
    "def generate_means(N, mean_load, var_load):\n",
    "    print('Mean Load:', mean_load, '; Variance Load:', var_load)\n",
    "    means_load = np.random.normal(loc=mean_load, scale=np.sqrt(var_load), size=N)\n",
    "    \n",
    "    # # Plotting means_load\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.plot(means_load, marker='o', linestyle='-', color='b', label='means_load')\n",
    "    # plt.title('Random Means for Load')\n",
    "    # plt.xlabel('Node')\n",
    "    # plt.ylabel('Mean Load')\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # \n",
    "    # # Adjust layout\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return means_load"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.209946Z",
     "start_time": "2024-08-11T05:58:46.201422Z"
    }
   },
   "id": "deef6ca56a0bbf34",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to generate IID data\n",
    "def generate_iid_data(N, T, means_load):\n",
    "    loads = np.array([np.random.normal(loc=means_load[i], scale=1, size=T) for i in range(N)])\n",
    "\n",
    "    return loads, np.mean(loads, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.216668Z",
     "start_time": "2024-08-11T05:58:46.209946Z"
    }
   },
   "id": "e09e7ab2735978ad",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to generate AR(1) data\n",
    "def generate_ar1_data(N, T, means_load, theta):\n",
    "    \"\"\"\n",
    "    Generate AR(1) data for multiple nodes.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of nodes.\n",
    "        T (int): Number of time steps.\n",
    "        means_load (array-like): Mean load for each node.\n",
    "        theta (float): AR(1) process parameter.\n",
    "    \n",
    "    Returns:\n",
    "        load (ndarray): Generated AR(1) load data.\n",
    "    \"\"\"\n",
    "    # print('Theta:', theta)\n",
    "    loads = np.zeros((N, T))\n",
    "\n",
    "    def generate_ar1(theta, T, mean_node):\n",
    "        \"\"\"\n",
    "        Generate a single AR(1) time series.\n",
    "        \n",
    "        Parameters:\n",
    "            theta (float): AR(1) process parameter.\n",
    "            n (int): Number of time steps.\n",
    "            mean_node (float): Mean load for the node.\n",
    "        \n",
    "        Returns:\n",
    "            ar1 (ndarray): Generated AR(1) time series.\n",
    "        \"\"\"\n",
    "        ar1 = np.zeros(T)\n",
    "        ar1[0] = mean_node\n",
    "        for t in range(1, T):\n",
    "            ar1[t] = theta * ar1[t - 1] + (1 - theta) * mean_node + np.random.normal(0, 1)\n",
    "        return ar1\n",
    "\n",
    "    for i in range(N):\n",
    "        loads[i] = generate_ar1(theta, T, means_load[i])\n",
    "\n",
    "    return loads, np.mean(loads, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.223273Z",
     "start_time": "2024-08-11T05:58:46.216668Z"
    }
   },
   "id": "165d92f11a9f74a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_reward_0(load):\n",
    "    # Simple reward function\n",
    "    return 1 / (1 + load_iid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.230276Z",
     "start_time": "2024-08-11T05:58:46.224277Z"
    }
   },
   "id": "34a04f728fb0e5a8",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 线性反转缩放 Linear inverse scaling\n",
    "def calculate_reward(load, alpha=1):\n",
    "    # Linear inverse scaling reward function.\n",
    "    return (np.max(load) - load) / (np.max(load) - np.min(load)) * alpha"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.237946Z",
     "start_time": "2024-08-11T05:58:46.231280Z"
    }
   },
   "id": "c75eba74149fbd9b",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "N = 10\n",
    "T = 1000\n",
    "mean_load = 50\n",
    "var_load = 10\n",
    "k_values = [1, 2, 5]\n",
    "thetas = [0.1, 0.5, 0.9]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.244877Z",
     "start_time": "2024-08-11T05:58:46.238950Z"
    }
   },
   "id": "23ccb6a3e7e0c136",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.258487Z",
     "start_time": "2024-08-11T05:58:46.244877Z"
    }
   },
   "id": "6b378cfe7957eb20",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Load: 50 ; Variance Load: 10\n"
     ]
    }
   ],
   "source": [
    "means_load = generate_means(N, mean_load, var_load)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.265058Z",
     "start_time": "2024-08-11T05:58:46.260494Z"
    }
   },
   "id": "412883340974e5fe",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Generate IID data\n",
    "load_iid, load_iid_means = generate_iid_data(N, T, means_load)\n",
    "load_reward_iid = calculate_reward(load_iid, 10)\n",
    "# load_reward_iid_means = calculate_reward(load_iid_means, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.271720Z",
     "start_time": "2024-08-11T05:58:46.266062Z"
    }
   },
   "id": "f61b1ddf5a82f6c3",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Generate AR(1) data\n",
    "# # load_ar1, load_ar1_means = generate_ar1_data(N, T, means_load, theta)\n",
    "# load_ar1_thetas = []\n",
    "# load_ar1_means_thetas = []\n",
    "# load_reward_ar1_thetas = []\n",
    "# load_reward_ar1_means_thetas = []\n",
    "# for theta in thetas:\n",
    "#     load_ar1_theta, load_ar1_means_theta = generate_ar1_data(N, T, means_load, theta)\n",
    "# \n",
    "#     load_reward_ar1_theta = calculate_reward(load_ar1_theta, 10)\n",
    "#     # load_reward_ar1_means_theta = calculate_reward(load_ar1_means_theta, 10)\n",
    "# \n",
    "#     load_ar1_thetas.append(load_ar1_theta)\n",
    "#     load_ar1_means_thetas.append(load_ar1_means_theta)\n",
    "#     load_reward_ar1_thetas.append(load_reward_ar1_theta)\n",
    "#     # load_reward_ar1_means_thetas.append(load_reward_ar1_means_theta)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.278571Z",
     "start_time": "2024-08-11T05:58:46.271720Z"
    }
   },
   "id": "9a91ef1f75dbae1",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LSTMExpert(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMExpert, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.290163Z",
     "start_time": "2024-08-11T05:58:46.279584Z"
    }
   },
   "id": "f08661e860325f58",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def prepare_data(rewards, time_steps):\n",
    "#     X, y = [], []\n",
    "#     for t in range(len(rewards) - time_steps):\n",
    "#         X.append(rewards[t:t + time_steps])\n",
    "#         y.append(rewards[t + time_steps])\n",
    "#     return np.array(X), np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.297161Z",
     "start_time": "2024-08-11T05:58:46.291167Z"
    }
   },
   "id": "3963abbd40013d90",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepare_data(rewards, time_steps):\n",
    "    X, y = [], []\n",
    "    for t in range(rewards.shape[1] - time_steps):\n",
    "        X.append(rewards[:, t:t + time_steps].T)\n",
    "        y.append(rewards[:, t + time_steps])\n",
    "    return np.array(X), np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.304798Z",
     "start_time": "2024-08-11T05:58:46.298166Z"
    }
   },
   "id": "2639097c9b33d3b4",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def train_lstm_models(rewards, num_experts, time_steps, input_size, hidden_size, output_size, epochs=10):\n",
    "#     models = [LSTMExpert(input_size, hidden_size, output_size).to(device) for _ in range(num_experts)]\n",
    "#     optimizers = [optim.Adam(model.parameters(), lr=0.01) for model in models]\n",
    "#     criterion = nn.MSELoss()\n",
    "# \n",
    "#     X, y = prepare_data(rewards, time_steps)\n",
    "#     X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "#     y = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "# \n",
    "#     for model, optimizer in zip(models, optimizers):\n",
    "#         for epoch in range(epochs):\n",
    "#             model.train()\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(X)\n",
    "#             loss = criterion(output, y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "# \n",
    "#     return models"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.312376Z",
     "start_time": "2024-08-11T05:58:46.305807Z"
    }
   },
   "id": "a59f92a41aa890e8",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_lstm_models(rewards, num_experts, time_steps, input_size, hidden_size, output_size, epochs=10):\n",
    "    models = [LSTMExpert(input_size, hidden_size, output_size).to(device) for _ in range(num_experts)]\n",
    "    optimizers = [optim.Adam(model.parameters(), lr=0.01) for model in models]\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    X, y = prepare_data(rewards, time_steps)\n",
    "    X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    y = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    for model, optimizer in zip(models, optimizers):\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return models\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.319880Z",
     "start_time": "2024-08-11T05:58:46.313381Z"
    }
   },
   "id": "7c97926842837532",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def exp4_with_lstm(rewards, lstm_models, gamma, alpha, time_steps):\n",
    "#     N, T = rewards.shape\n",
    "#     K = len(lstm_models)\n",
    "# \n",
    "#     # 初始化权重\n",
    "#     weights = np.ones(K)\n",
    "# \n",
    "#     all_regrets = []\n",
    "#     all_actions = []\n",
    "#     all_expert_weights = []\n",
    "# \n",
    "#     optimal_reward = np.max(np.mean(rewards, axis=1))\n",
    "# \n",
    "#     # 准备时间序列数据\n",
    "#     history = np.zeros((time_steps, N))\n",
    "# \n",
    "#     for t in range(T):\n",
    "#         # 更新历史数据\n",
    "#         if t >= time_steps:\n",
    "#             history = np.roll(history, -1, axis=0)\n",
    "#             history[-1, :] = rewards[:, t]\n",
    "# \n",
    "#         if t < time_steps:\n",
    "#             expert_advice = np.random.rand(K, N)\n",
    "#         else:\n",
    "#             # 使用LSTM模型预测奖励\n",
    "#             history_tensor = torch.tensor(history[np.newaxis, :, :], dtype=torch.float32).to(device)\n",
    "#             expert_advice = np.array([model(history_tensor).cpu().detach().numpy()[0] for model in lstm_models])\n",
    "# \n",
    "#         # 计算专家的权重分布\n",
    "#         expert_weights = weights / np.sum(weights)\n",
    "# \n",
    "#         # 计算每个臂的选择概率\n",
    "#         probabilities = np.dot(expert_weights, expert_advice)\n",
    "#         probabilities = (1 - gamma) * probabilities + gamma / N\n",
    "# \n",
    "#         # 选择一个臂\n",
    "#         action = np.random.choice(N, p=probabilities)\n",
    "#         reward = rewards[action, t]\n",
    "# \n",
    "#         # 更新权重\n",
    "#         estimated_reward = reward / probabilities[action]\n",
    "#         for k in range(K):\n",
    "#             weights[k] *= np.exp(alpha * expert_advice[k, action] * estimated_reward / N)\n",
    "# \n",
    "#         # 记录\n",
    "#         all_actions.append(action)\n",
    "#         all_regrets.append(optimal_reward - reward)\n",
    "#         all_expert_weights.append(expert_weights.copy())\n",
    "# \n",
    "#     return np.array(all_actions), np.array(all_regrets), np.array(all_expert_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.327471Z",
     "start_time": "2024-08-11T05:58:46.320884Z"
    }
   },
   "id": "de4adcbfe8349ae7",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def exp4_with_lstm(rewards, lstm_models, gamma, alpha, time_steps):\n",
    "    N, T = rewards.shape\n",
    "    K = len(lstm_models)\n",
    "\n",
    "    weights = np.ones(K)\n",
    "\n",
    "    all_regrets = []\n",
    "    all_actions = []\n",
    "    all_expert_weights = []\n",
    "\n",
    "    optimal_reward = np.max(np.mean(rewards, axis=1))\n",
    "\n",
    "    history = np.zeros((time_steps, N))\n",
    "\n",
    "    for t in range(T):\n",
    "        if t >= time_steps:\n",
    "            history = np.roll(history, -1, axis=0)\n",
    "            history[-1, :] = rewards[:, t]\n",
    "\n",
    "        if t < time_steps:\n",
    "            expert_advice = np.random.rand(K, N)\n",
    "        else:\n",
    "            history_tensor = torch.tensor(history[np.newaxis, :, :], dtype=torch.float32).to(device)\n",
    "            expert_advice = np.array([model(history_tensor).cpu().detach().numpy()[0] for model in lstm_models])\n",
    "\n",
    "        expert_weights = weights / np.sum(weights)\n",
    "\n",
    "        probabilities = np.dot(expert_weights, expert_advice)\n",
    "        probabilities = (1 - gamma) * probabilities + gamma / N\n",
    "\n",
    "        # 归一化概率以确保其和为1\n",
    "        probabilities /= np.sum(probabilities)\n",
    "\n",
    "        action = np.random.choice(N, p=probabilities)\n",
    "        reward = rewards[action, t]\n",
    "\n",
    "        estimated_reward = reward / probabilities[action]\n",
    "        for k in range(K):\n",
    "            weights[k] *= np.exp(alpha * expert_advice[k, action] * estimated_reward / N)\n",
    "\n",
    "        all_actions.append(action)\n",
    "        all_regrets.append(optimal_reward - reward)\n",
    "        all_expert_weights.append(expert_weights.copy())\n",
    "\n",
    "    return np.array(all_actions), np.array(all_regrets), np.array(all_expert_weights)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:46.338988Z",
     "start_time": "2024-08-11T05:58:46.328475Z"
    }
   },
   "id": "dfa09861a525573c",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_36500\\2046463271.py:39: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  weights[k] *= np.exp(alpha * expert_advice[k, action] * estimated_reward / N)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_36500\\2046463271.py:26: RuntimeWarning: invalid value encountered in divide\n",
      "  expert_weights = weights / np.sum(weights)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# 运行EXP4算法\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m actions, regrets, expert_weights \u001B[38;5;241m=\u001B[39m exp4_with_lstm(rewards, lstm_models, gamma, alpha, time_steps)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# 绘制结果\u001B[39;00m\n\u001B[0;32m     23\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m6\u001B[39m))\n",
      "Cell \u001B[1;32mIn[24], line 34\u001B[0m, in \u001B[0;36mexp4_with_lstm\u001B[1;34m(rewards, lstm_models, gamma, alpha, time_steps)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# 归一化概率以确保其和为1\u001B[39;00m\n\u001B[0;32m     32\u001B[0m probabilities \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(probabilities)\n\u001B[1;32m---> 34\u001B[0m action \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(N, p\u001B[38;5;241m=\u001B[39mprobabilities)\n\u001B[0;32m     35\u001B[0m reward \u001B[38;5;241m=\u001B[39m rewards[action, t]\n\u001B[0;32m     37\u001B[0m estimated_reward \u001B[38;5;241m=\u001B[39m reward \u001B[38;5;241m/\u001B[39m probabilities[action]\n",
      "File \u001B[1;32mnumpy\\\\random\\\\mtrand.pyx:970\u001B[0m, in \u001B[0;36mnumpy.random.mtrand.RandomState.choice\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "# 示例数据\n",
    "N = 10  # 臂的数量\n",
    "T = 1000  # 时间步数\n",
    "K = 5  # 专家的数量\n",
    "time_steps = 10  # LSTM 模型的时间步\n",
    "\n",
    "rewards = load_reward_iid\n",
    "\n",
    "# 训练LSTM模型\n",
    "input_size = N\n",
    "hidden_size = 50\n",
    "output_size = N\n",
    "lstm_models = train_lstm_models(rewards, K, time_steps, input_size, hidden_size, output_size)\n",
    "\n",
    "# 设置参数\n",
    "gamma = 0.1\n",
    "alpha = 0.1\n",
    "\n",
    "# 运行EXP4算法\n",
    "actions, regrets, expert_weights = exp4_with_lstm(rewards, lstm_models, gamma, alpha, time_steps)\n",
    "\n",
    "# 绘制结果\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.cumsum(regrets))\n",
    "plt.title('Cumulative Regrets of EXP4 with LSTM')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-11T05:58:48.383927Z",
     "start_time": "2024-08-11T05:58:46.339992Z"
    }
   },
   "id": "3a994b3226c45fb1",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMExpert(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMExpert, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def prepare_data(rewards, time_steps):\n",
    "    X, y = [], []\n",
    "    for t in range(rewards.shape[1] - time_steps):\n",
    "        X.append(rewards[:, t:t + time_steps].T)\n",
    "        y.append(rewards[:, t + time_steps])\n",
    "    return np.array(X), np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-11T05:58:48.384931Z"
    }
   },
   "id": "4392565735cd3902",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "def train_lstm_models(rewards, num_experts, time_steps, input_size, hidden_size, output_size, epochs=10):\n",
    "    models = [LSTMExpert(input_size, hidden_size, output_size).to(device) for _ in range(num_experts)]\n",
    "    optimizers = [optim.Adam(model.parameters(), lr=0.01) for model in models]\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    X, y = prepare_data(rewards, time_steps)\n",
    "    X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    y = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    for model, optimizer in zip(models, optimizers):\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a5ce0064cb3de88"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_lstm_models(rewards, num_experts, time_steps, input_size, hidden_size, output_size, epochs=10):\n",
    "    models = [LSTMExpert(input_size, hidden_size, output_size).to(device) for _ in range(num_experts)]\n",
    "    optimizers = [optim.Adam(model.parameters(), lr=0.01) for model in models]\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    X, y = prepare_data(rewards, time_steps)\n",
    "    X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    y = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    for model_idx, (model, optimizer) in enumerate(zip(models, optimizers)):\n",
    "        print(f\"Training model {model_idx + 1}/{num_experts}\")\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"Model {model_idx + 1}, Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    return models\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-11T05:58:48.384931Z"
    }
   },
   "id": "ae4e09e625ba3050",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_top_k_accuracy(actions, rewards_means, k):\n",
    "    optimal_actions = np.argsort(rewards_means)[-k:]\n",
    "    return np.mean(np.isin(actions, optimal_actions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-11T05:58:48.385931Z"
    }
   },
   "id": "dbff693ba3770c4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def exp4_with_lstm(rewards, lstm_models, gamma, alpha, time_steps):\n",
    "    N, T = rewards.shape\n",
    "    K = len(lstm_models)\n",
    "\n",
    "    log_weights = np.zeros(K)  # 在对数空间初始化权重\n",
    "\n",
    "    all_regrets = []\n",
    "    all_actions = []\n",
    "    all_expert_weights = []\n",
    "\n",
    "    optimal_reward = np.max(np.mean(rewards, axis=1))\n",
    "\n",
    "    history = np.zeros((time_steps, N))\n",
    "\n",
    "    for t in range(T):\n",
    "        if t >= time_steps:\n",
    "            history = np.roll(history, -1, axis=0)\n",
    "            history[-1, :] = rewards[:, t]\n",
    "\n",
    "        if t < time_steps:\n",
    "            expert_advice = np.random.rand(K, N)\n",
    "        else:\n",
    "            history_tensor = torch.tensor(history[np.newaxis, :, :], dtype=torch.float32).to(device)\n",
    "            expert_advice = np.array([model(history_tensor).cpu().detach().numpy()[0] for model in lstm_models])\n",
    "\n",
    "        expert_weights = np.exp(log_weights - np.max(log_weights))  # 防止数值溢出\n",
    "        expert_weights /= np.sum(expert_weights)\n",
    "        expert_weights = np.nan_to_num(expert_weights)\n",
    "\n",
    "        probabilities = np.dot(expert_weights, expert_advice)\n",
    "        probabilities = (1 - gamma) * probabilities + gamma / N\n",
    "        probabilities = np.nan_to_num(probabilities)\n",
    "\n",
    "        probabilities /= np.sum(probabilities)\n",
    "\n",
    "        action = np.random.choice(N, p=probabilities)\n",
    "        reward = rewards[action, t]\n",
    "\n",
    "        estimated_reward = reward / probabilities[action]\n",
    "        for k in range(K):\n",
    "            log_weights[k] += alpha * expert_advice[k, action] * estimated_reward / N  # 更新在对数空间\n",
    "\n",
    "        all_actions.append(action)\n",
    "        all_regrets.append(optimal_reward - reward)\n",
    "        all_expert_weights.append(expert_weights.copy())\n",
    "\n",
    "    accuracies = {k: calculate_top_k_accuracy(actions, rewards_means, k) for k in k_values}\n",
    "    \n",
    "    return np.array(all_actions), np.array(all_regrets), np.array(all_expert_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-11T05:58:48.386931Z"
    }
   },
   "id": "a9170228d710a05a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# 示例数据\n",
    "N = 10  # 臂的数量\n",
    "T = 1000  # 时间步数\n",
    "K = 5  # 专家的数量\n",
    "time_steps = 10  # LSTM 模型的时间步\n",
    "\n",
    "rewards = load_reward_iid\n",
    "\n",
    "# 训练LSTM模型\n",
    "input_size = N\n",
    "hidden_size = 50\n",
    "output_size = N\n",
    "lstm_models = train_lstm_models(rewards, K, time_steps, input_size, hidden_size, output_size)\n",
    "\n",
    "# 设置参数\n",
    "gamma = 0.1\n",
    "alpha = 0.1\n",
    "\n",
    "# 运行EXP4算法\n",
    "actions, regrets, expert_weights = exp4_with_lstm(rewards, lstm_models, gamma, alpha, time_steps)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-11T05:58:48.386931Z"
    }
   },
   "id": "11a0405998d6a63",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "actions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-11T05:58:48.387931Z"
    }
   },
   "id": "c8c1b55ef933b109"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "regrets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-11T05:58:48.387931Z"
    }
   },
   "id": "ea7c1a76775f4c5c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "expert_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-11T05:58:48.388931Z"
    }
   },
   "id": "6a0837e7daa2377d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 绘制结果\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.cumsum(regrets))\n",
    "plt.title('Cumulative Regrets of EXP4 with LSTM')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Cumulative Regret')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-11T05:58:48.389931Z"
    }
   },
   "id": "f048b655ab9ab6b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
