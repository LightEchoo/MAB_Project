{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4a40d-f456-4dd3-85f2-750d96368d90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataGenerateConfig:\n",
    "    mean_load: float = 50.0  # Mean load of nodes' load\n",
    "    var_load: float = 10.0  # Variance load of nodes' load\n",
    "    iid_var: float = 1.0  # Variance for iid data\n",
    "    theta: float = 0.9  # AR(1) parameter\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ARConfig:\n",
    "    order: int = 5  # AR order\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LSTMConfig:\n",
    "    hidden_size: int = 64  # Hidden size\n",
    "    num_layers: int = 4  # Number of layers\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GATConfig:\n",
    "    hidden_size: int = 32  # Hidden size\n",
    "    num_heads: int = 8  # Number of attention heads\n",
    "    num_gat_layers: int = 3  # Number of GAT layers\n",
    "\n",
    "@dataclass\n",
    "class GNNConfig:\n",
    "    hidden_size: int = 32\n",
    "    num_layers: int = 3\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    N: int = 10  # Number of nodes\n",
    "    T_train_val: int = 10000  # Training and validation time steps\n",
    "    T_test: int = 1000  # Test time steps\n",
    "    data_type: str = 'ar1'  # 'iid' or 'ar1'\n",
    "\n",
    "    batch_size: int = 64  # Batch size\n",
    "    seq_length: int = 20  # Sequence length\n",
    "    input_size: int = 10  # Input size\n",
    "    output_size: int = 10  # Output size\n",
    "    learning_rate: float = 0.001  # Learning rate\n",
    "    num_epochs: int = 100  # Number of epochs\n",
    "    num_workers: int = 24  # Number of workers for DataLoader\n",
    "    device: str = 'cuda'  # Device\n",
    "    mix_precision: bool = True  # Mixed precision training\n",
    "\n",
    "    # 早停的参数\n",
    "    patience_epochs: int=6  # 'patience_epochs' 个 epoch 没有提升，就停止训练\n",
    "    min_delta: float=1e-2  # 当监控指标的变化小于 min_delta 时，就视为没有提升\n",
    "\n",
    "    # 调度器的参数\n",
    "    mode: str='min'  # 'min' 表示监控指标的值越小越好，'max' 表示监控指标的值越大越好\n",
    "    factor: float=0.1  # 学习率调度器的缩放因子\n",
    "    patience_lr: int=2  # 'patience_lr' 个 epoch 没有提升，就缩放学习率\n",
    "    min_lr: float=1e-6  # 学习率的下限\n",
    "    threshold: float=1e-2  # 监控指标的变化小于 threshold 时，就视为没有提升\n",
    "\n",
    "    # 使用 default_factory 来实例化复杂类型\n",
    "    dg_config: DataGenerateConfig = field(default_factory=DataGenerateConfig)\n",
    "    ar_config: ARConfig = field(default_factory=ARConfig)\n",
    "    lstm_config: LSTMConfig = field(default_factory=LSTMConfig)\n",
    "    gat_config: GATConfig = field(default_factory=GATConfig)\n",
    "    gnn_config: GNNConfig = field(default_factory=GNNConfig)\n",
    "\n",
    "    def print_config_info(self):\n",
    "        print(\"Config settings:\")\n",
    "        self._recursive_print(vars(self))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    def _recursive_print(self, config_dict, indent=0):\n",
    "        for key, value in config_dict.items():\n",
    "            if isinstance(value, (DataGenerateConfig, ARConfig, LSTMConfig, GATConfig)):\n",
    "                print(\" \" * indent + f\"{key}:\")\n",
    "                self._recursive_print(vars(value), indent + 4)\n",
    "            else:\n",
    "                print(\" \" * indent + f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "class DataGenerate:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config  # 配置\n",
    "        self.means_loads = self._generate_means()  # 生成节点的平均负载\n",
    "\n",
    "        self.load_iid, self.mean_iid = self._generate_iid_data()  # 生成iid数据\n",
    "        self.load_ar1, self.mean_ar1 = self._generate_ar1_data()  # 生成ar1数据\n",
    "\n",
    "        self._save_data()  # 保存数据\n",
    "\n",
    "        self.print_data_generate_info()  # 打印信息\n",
    "        self.plot_original_means()  # 绘制原始平均负载\n",
    "\n",
    "    def plot_original_means(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.means_loads, marker='o', linestyle='-', color='b', label='means_load')\n",
    "        plt.title('Original Random Means of Nodes of Load')\n",
    "        plt.xlabel('Node')\n",
    "        plt.ylabel('Mean Load')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def _generate_means(self):\n",
    "        return np.random.normal(self.config.dg_config.mean_load, self.config.dg_config.var_load, size=(self.config.N,))\n",
    "\n",
    "    def _generate_iid_data(self):\n",
    "        loads = np.array([np.random.normal(loc=self.means_loads[i], scale=self.config.dg_config.iid_var,\n",
    "                                           size=self.config.T_train_val + self.config.T_test) for i in\n",
    "                          range(self.config.N)])\n",
    "        return loads, np.mean(loads, axis=1)\n",
    "\n",
    "    def _generate_ar1_data(self):\n",
    "        loads = np.zeros((self.config.N, self.config.T_train_val + self.config.T_test))\n",
    "\n",
    "        def generate_ar1(mean_node):\n",
    "            ar1 = torch.zeros(self.config.T_train_val + self.config.T_test)\n",
    "            ar1[0] = mean_node\n",
    "            for t in range(1, self.config.T_train_val + self.config.T_test):\n",
    "                ar1[t] = self.config.dg_config.theta * ar1[t - 1] + (\n",
    "                        1 - self.config.dg_config.theta) * mean_node + np.random.normal(0, 1)\n",
    "            return ar1\n",
    "\n",
    "        for i in range(self.config.N):\n",
    "            loads[i] = generate_ar1(self.means_loads[i])\n",
    "\n",
    "        return loads, np.mean(loads, axis=1)\n",
    "\n",
    "    def _save_data(self):\n",
    "        pd.DataFrame(self.load_iid).to_csv('load_iid_data.csv', index=False)\n",
    "        pd.DataFrame(self.load_ar1).to_csv('load_ar1_data.csv', index=False)\n",
    "\n",
    "    def print_data_generate_info(self):\n",
    "        print('means_loads:', self.means_loads.shape)\n",
    "        print('load_iid:', self.load_iid.shape)\n",
    "        print('mean_iid:', self.mean_iid.shape)\n",
    "        print('load_ar1:', self.load_ar1.shape)\n",
    "        print('mean_ar1:', self.mean_ar1.shape)\n",
    "        print('edge_index:', self.edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d3101-d182-47e0-ba8a-0639fde9bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainVaildManage:\n",
    "    def __init_(self, config: Config):\n",
    "        self.config = config\n",
    "        self.load_iid = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataGenerateConfig:\n",
    "    mean_load: float = 50.0  # Mean load of nodes' load\n",
    "    var_load: float = 10.0  # Variance load of nodes' load\n",
    "    iid_var: float = 1.0  # Variance for iid data\n",
    "    theta: float = 0.9  # AR(1) parameter\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ARConfig:\n",
    "    order: int = 5  # AR order\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LSTMConfig:\n",
    "    hidden_size: int = 64  # Hidden size\n",
    "    num_layers: int = 4  # Number of layers\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GATConfig:\n",
    "    hidden_size: int = 32  # Hidden size\n",
    "    num_heads: int = 8  # Number of attention heads\n",
    "    num_gat_layers: int = 3  # Number of GAT layers\n",
    "\n",
    "@dataclass\n",
    "class GNNConfig:\n",
    "    hidden_size: int = 32\n",
    "    num_layers: int = 3\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    N: int = 10  # Number of nodes\n",
    "    T_train_val: int = 10000  # Training and validation time steps\n",
    "    T_test: int = 1000  # Test time steps\n",
    "    data_type: str = 'ar1'  # 'iid' or 'ar1'\n",
    "\n",
    "    batch_size: int = 64  # Batch size\n",
    "    seq_length: int = 20  # Sequence length\n",
    "    input_size: int = 10  # Input size\n",
    "    output_size: int = 10  # Output size\n",
    "    learning_rate: float = 0.001  # Learning rate\n",
    "    num_epochs: int = 100  # Number of epochs\n",
    "    num_workers: int = 24  # Number of workers for DataLoader\n",
    "    device: str = 'cuda'  # Device\n",
    "    mix_precision: bool = True  # Mixed precision training\n",
    "\n",
    "    # 早停的参数\n",
    "    patience_epochs: int=6  # 'patience_epochs' 个 epoch 没有提升，就停止训练\n",
    "    min_delta: float=1e-2  # 当监控指标的变化小于 min_delta 时，就视为没有提升\n",
    "\n",
    "    # 调度器的参数\n",
    "    mode: str='min'  # 'min' 表示监控指标的值越小越好，'max' 表示监控指标的值越大越好\n",
    "    factor: float=0.1  # 学习率调度器的缩放因子\n",
    "    patience_lr: int=2  # 'patience_lr' 个 epoch 没有提升，就缩放学习率\n",
    "    min_lr: float=1e-6  # 学习率的下限\n",
    "    threshold: float=1e-2  # 监控指标的变化小于 threshold 时，就视为没有提升\n",
    "\n",
    "    # 使用 default_factory 来实例化复杂类型\n",
    "    dg_config: DataGenerateConfig = field(default_factory=DataGenerateConfig)\n",
    "    ar_config: ARConfig = field(default_factory=ARConfig)\n",
    "    lstm_config: LSTMConfig = field(default_factory=LSTMConfig)\n",
    "    gat_config: GATConfig = field(default_factory=GATConfig)\n",
    "    gnn_config: GNNConfig = field(default_factory=GNNConfig)\n",
    "\n",
    "    def print_config_info(self):\n",
    "        print(\"Config settings:\")\n",
    "        self._recursive_print(vars(self))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    def _recursive_print(self, config_dict, indent=0):\n",
    "        for key, value in config_dict.items():\n",
    "            if isinstance(value, (DataGenerateConfig, ARConfig, LSTMConfig, GATConfig)):\n",
    "                print(\" \" * indent + f\"{key}:\")\n",
    "                self._recursive_print(vars(value), indent + 4)\n",
    "            else:\n",
    "                print(\" \" * indent + f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "class DataGenerate:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config  # 配置\n",
    "        self.means_loads = self._generate_means()  # 生成节点的平均负载\n",
    "\n",
    "        self.load_iid, self.mean_iid = self._generate_iid_data()  # 生成iid数据\n",
    "        self.load_ar1, self.mean_ar1 = self._generate_ar1_data()  # 生成ar1数据\n",
    "\n",
    "        self._save_data()  # 保存数据\n",
    "\n",
    "        self.print_data_generate_info()  # 打印信息\n",
    "        self.plot_original_means()  # 绘制原始平均负载\n",
    "\n",
    "    def plot_original_means(self):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.means_loads, marker='o', linestyle='-', color='b', label='means_load')\n",
    "        plt.title('Original Random Means of Nodes of Load')\n",
    "        plt.xlabel('Node')\n",
    "        plt.ylabel('Mean Load')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def _generate_means(self):\n",
    "        return np.random.normal(self.config.dg_config.mean_load, self.config.dg_config.var_load, size=(self.config.N,))\n",
    "\n",
    "    def _generate_iid_data(self):\n",
    "        loads = np.array([np.random.normal(loc=self.means_loads[i], scale=self.config.dg_config.iid_var,\n",
    "                                           size=self.config.T_train_val + self.config.T_test) for i in\n",
    "                          range(self.config.N)])\n",
    "        return loads, np.mean(loads, axis=1)\n",
    "\n",
    "    def _generate_ar1_data(self):\n",
    "        loads = np.zeros((self.config.N, self.config.T_train_val + self.config.T_test))\n",
    "\n",
    "        def generate_ar1(mean_node):\n",
    "            ar1 = torch.zeros(self.config.T_train_val + self.config.T_test)\n",
    "            ar1[0] = mean_node\n",
    "            for t in range(1, self.config.T_train_val + self.config.T_test):\n",
    "                ar1[t] = self.config.dg_config.theta * ar1[t - 1] + (\n",
    "                        1 - self.config.dg_config.theta) * mean_node + np.random.normal(0, 1)\n",
    "            return ar1\n",
    "\n",
    "        for i in range(self.config.N):\n",
    "            loads[i] = generate_ar1(self.means_loads[i])\n",
    "\n",
    "        return loads, np.mean(loads, axis=1)\n",
    "\n",
    "    def _save_data(self):\n",
    "        pd.DataFrame(self.load_iid).to_csv('load_iid_data.csv', index=False)\n",
    "        pd.DataFrame(self.load_ar1).to_csv('load_ar1_data.csv', index=False)\n",
    "\n",
    "    def print_data_generate_info(self):\n",
    "        print('means_loads:', self.means_loads.shape)\n",
    "        print('load_iid:', self.load_iid.shape)\n",
    "        print('mean_iid:', self.mean_iid.shape)\n",
    "        print('load_ar1:', self.load_ar1.shape)\n",
    "        print('mean_ar1:', self.mean_ar1.shape)\n",
    "        print('edge_index:', self.edge_index.shape)\n",
    "\n",
    "\n",
    "class DataManage:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config  # 配置\n",
    "        self.load_iid = pd.read_csv('load_iid_data.csv').values  # 加载iid数据, shape: (N, T), 10*11000\n",
    "        self.load_ar1 = pd.read_csv('load_ar1_data.csv').values  # 加载ar1数据, shape: (N, T), 10*11000\n",
    "\n",
    "        if self.config.data_type == 'iid':\n",
    "            self.data = self.load_iid\n",
    "        elif self.config.data_type == 'ar1':\n",
    "            self.data = self.load_ar1\n",
    "\n",
    "        self.train_val_data = self.data[:, :self.config.T_train_val]  # 训练集和验证集数据, shape: (N, T_train_val), 10*10000\n",
    "        self.test_data = self.data[:, self.config.T_train_val:]  # 测试集数据, shape: (N, T_test), 10*1000\n",
    "\n",
    "        # 获取训练集和验证集的数据\n",
    "        self.train_sets, self.val_sets = self._create_sequences()\n",
    "\n",
    "        # 创建数据集\n",
    "        self.train_val_dataset = TensorDataset(self.train_sets, self.val_sets)\n",
    "        self.dataloader = DataLoader(self.train_val_dataset, batch_size=self.config.batch_size, shuffle=True,\n",
    "                                     num_workers=self.config.num_workers)\n",
    "\n",
    "        self.print_data_manage_info()  # 打印信息\n",
    "        self.print_dataloader_info()  # 打印dataloader信息\n",
    "\n",
    "        self.train_val_data = torch.tensor(self.train_val_data, device=self.config.device, dtype=torch.float32)\n",
    "        self.test_data = torch.tensor(self.test_data, device=self.config.device, dtype=torch.float32)\n",
    "\n",
    "        self.edge_index = torch.tensor(np.array([(i, j) for i in range(self.config.N) for j in range(self.config.N)]).T,\n",
    "                                       dtype=torch.long)  # 默认全连接图\n",
    "\n",
    "    def _create_sequences(self):\n",
    "        train_sets = []\n",
    "        val_sets = []\n",
    "        for i in range(self.config.T_train_val - self.config.seq_length):\n",
    "            # 循环次数不是T_train - seq_length + 1，因为训练集里并没有第10001个真实数据作为target。\n",
    "            # 最后一次生成的序列会在逐步更新的过程中使用，而不是在初始训练集中。\n",
    "            train = self.train_val_data[:, i: i + self.config.seq_length].T  # 提取每个时间步的序列\n",
    "            val = self.train_val_data[:, i + self.config.seq_length]  # 提取目标值\n",
    "            train_sets.append(train)\n",
    "            val_sets.append(val)\n",
    "        return torch.tensor(np.array(train_sets)), torch.tensor(np.array(val_sets))\n",
    "\n",
    "    # 绘制指定范围内的数据\n",
    "    def plot_range_data(self, data, start, end, title='Load Data'):\n",
    "        time_steps = np.arange(start, end)\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for i in range(data.shape[0]):\n",
    "            plt.plot(time_steps, data[i, start:end], label=f'Node {i}')\n",
    "        plt.title(f'{title} - Nodes {0}-{data.shape[0]}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Load')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def print_data_manage_info(self):\n",
    "        print('load_iid.shape:', self.load_iid.shape)\n",
    "        print('load_iid.type:', type(self.load_iid))\n",
    "        print('load_ar1.shape:', self.load_ar1.shape)\n",
    "        print('load_ar1.type:', type(self.load_ar1))\n",
    "        print('data.shape:', self.data.shape)\n",
    "        print('data.type:', type(self.data))\n",
    "        print('train_val_data.shape:', self.train_val_data.shape)\n",
    "        print('train_val_data.type:', type(self.train_val_data))\n",
    "        print('test_data.shape:', self.test_data.shape)\n",
    "        print('test_data.type:', type(self.test_data))\n",
    "        print('train_sets.shape:', self.train_sets.shape)\n",
    "        print('train_sets.type:', type(self.train_sets))\n",
    "        print('val_sets.shape:', self.val_sets.shape)\n",
    "        print('val_sets.type:', type(self.val_sets))\n",
    "        print('len(train_val_dataset):', len(self.train_val_dataset))\n",
    "        print('len(dataloader):', len(self.dataloader))\n",
    "\n",
    "    def print_dataloader_info(self):\n",
    "        for i, (train, val) in enumerate(self.dataloader):\n",
    "            if i % 30 == 0 or i == len(self.dataloader) - 1:  # 每30次打印一次，确保最后一次打印\n",
    "                print(f'i: {i:>3}, train: {train.shape}, val: {val.shape}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    RE_GENERATE_DATA = False  # 是否重新生成数据\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # device = 'cpu'\n",
    "\n",
    "    # 默认配置\n",
    "    config = Config(\n",
    "        N=10,\n",
    "        T_train_val=10000,\n",
    "        T_test=1000,\n",
    "        data_type='ar1',\n",
    "\n",
    "        batch_size=64,\n",
    "        seq_length=20,\n",
    "        input_size=10,\n",
    "        output_size=10,\n",
    "        learning_rate=0.001,\n",
    "        num_epochs=100,\n",
    "        num_workers=24,\n",
    "        device=device,\n",
    "        mix_precision=True if device == 'cuda' else False,\n",
    "\n",
    "        patience_epochs=6,\n",
    "        min_delta=1e-2,\n",
    "\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience_lr=2,\n",
    "        min_lr=1e-6,\n",
    "        threshold=1e-2,\n",
    "\n",
    "        dg_config=DataGenerateConfig(mean_load=50.0, var_load=10.0, iid_var=1.0, theta=0.9),\n",
    "        ar_config=ARConfig(order=5),\n",
    "        lstm_config=LSTMConfig(hidden_size=64, num_layers=4),\n",
    "        gat_config=GATConfig(hidden_size=32, num_heads=8, num_gat_layers=3),\n",
    "        gnn_config=GNNConfig(hidden_size=32, num_layers=3)\n",
    "\n",
    "    )\n",
    "\n",
    "    config.print_config_info()\n",
    "\n",
    "    if RE_GENERATE_DATA:\n",
    "        data_generate = DataGenerate(config)\n",
    "\n",
    "    data_manage = DataManage(config)\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e15cd-3c82-4233-8b28-f2b2f09a1fdb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataManage:\n",
    "    def __init__(self, config: Config):\n",
    "        self.config = config  # 配置\n",
    "        self.load_iid = pd.read_csv('load_iid_data.csv').values  # 加载iid数据, shape: (N, T), 10*11000\n",
    "        self.load_ar1 = pd.read_csv('load_ar1_data.csv').values  # 加载ar1数据, shape: (N, T), 10*11000\n",
    "\n",
    "        if self.config.data_type == 'iid':\n",
    "            self.data = self.load_iid\n",
    "        elif self.config.data_type == 'ar1':\n",
    "            self.data = self.load_ar1\n",
    "\n",
    "        self.train_val_data = self.data[:, :self.config.T_train_val]  # 训练集和验证集数据, shape: (N, T_train_val), 10*10000\n",
    "        self.test_data = self.data[:, self.config.T_train_val:]  # 测试集数据, shape: (N, T_test), 10*1000\n",
    "\n",
    "        # 获取训练集和验证集的数据\n",
    "        self.train_sets, self.val_sets = self._create_sequences()\n",
    "\n",
    "        # 创建数据集\n",
    "        self.train_val_dataset = TensorDataset(self.train_sets, self.val_sets)\n",
    "        self.dataloader = DataLoader(self.train_val_dataset, batch_size=self.config.batch_size, shuffle=True,\n",
    "                                     num_workers=self.config.num_workers)\n",
    "\n",
    "        self.print_data_manage_info()  # 打印信息\n",
    "        self.print_dataloader_info()  # 打印dataloader信息\n",
    "\n",
    "        self.train_val_data = torch.tensor(self.train_val_data, device=self.config.device, dtype=torch.float32)\n",
    "        self.test_data = torch.tensor(self.test_data, device=self.config.device, dtype=torch.float32)\n",
    "\n",
    "        self.edge_index = torch.tensor(np.array([(i, j) for i in range(self.config.N) for j in range(self.config.N)]).T,\n",
    "                                       dtype=torch.long)  # 默认全连接图\n",
    "\n",
    "    def _create_sequences(self):\n",
    "        train_sets = []\n",
    "        val_sets = []\n",
    "        for i in range(self.config.T_train_val - self.config.seq_length):\n",
    "            # 循环次数不是T_train - seq_length + 1，因为训练集里并没有第10001个真实数据作为target。\n",
    "            # 最后一次生成的序列会在逐步更新的过程中使用，而不是在初始训练集中。\n",
    "            train = self.train_val_data[:, i: i + self.config.seq_length].T  # 提取每个时间步的序列\n",
    "            val = self.train_val_data[:, i + self.config.seq_length]  # 提取目标值\n",
    "            train_sets.append(train)\n",
    "            val_sets.append(val)\n",
    "        return torch.tensor(np.array(train_sets)), torch.tensor(np.array(val_sets))\n",
    "\n",
    "    # 绘制指定范围内的数据\n",
    "    def plot_range_data(self, data, start, end, title='Load Data'):\n",
    "        time_steps = np.arange(start, end)\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for i in range(data.shape[0]):\n",
    "            plt.plot(time_steps, data[i, start:end], label=f'Node {i}')\n",
    "        plt.title(f'{title} - Nodes {0}-{data.shape[0]}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Load')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def print_data_manage_info(self):\n",
    "        print('load_iid.shape:', self.load_iid.shape)\n",
    "        print('load_iid.type:', type(self.load_iid))\n",
    "        print('load_ar1.shape:', self.load_ar1.shape)\n",
    "        print('load_ar1.type:', type(self.load_ar1))\n",
    "        print('data.shape:', self.data.shape)\n",
    "        print('data.type:', type(self.data))\n",
    "        print('train_val_data.shape:', self.train_val_data.shape)\n",
    "        print('train_val_data.type:', type(self.train_val_data))\n",
    "        print('test_data.shape:', self.test_data.shape)\n",
    "        print('test_data.type:', type(self.test_data))\n",
    "        print('train_sets.shape:', self.train_sets.shape)\n",
    "        print('train_sets.type:', type(self.train_sets))\n",
    "        print('val_sets.shape:', self.val_sets.shape)\n",
    "        print('val_sets.type:', type(self.val_sets))\n",
    "        print('len(train_val_dataset):', len(self.train_val_dataset))\n",
    "        print('len(dataloader):', len(self.dataloader))\n",
    "\n",
    "    def print_dataloader_info(self):\n",
    "        for i, (train, val) in enumerate(self.dataloader):\n",
    "            if i % 30 == 0 or i == len(self.dataloader) - 1:  # 每30次打印一次，确保最后一次打印\n",
    "                print(f'i: {i:>3}, train: {train.shape}, val: {val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd793bf-b9b2-4b24-a6ca-b2e1e8c2c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    RE_GENERATE_DATA = False  # 是否重新生成数据\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # device = 'cpu'\n",
    "\n",
    "    # 默认配置\n",
    "    config = Config(\n",
    "        N=10,\n",
    "        T_train_val=10000,\n",
    "        T_test=1000,\n",
    "        data_type='ar1',\n",
    "\n",
    "        batch_size=64,\n",
    "        seq_length=20,\n",
    "        input_size=10,\n",
    "        output_size=10,\n",
    "        learning_rate=0.001,\n",
    "        num_epochs=100,\n",
    "        num_workers=24,\n",
    "        device=device,\n",
    "        mix_precision=True if device == 'cuda' else False,\n",
    "\n",
    "        patience_epochs=6,\n",
    "        min_delta=1e-2,\n",
    "\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience_lr=2,\n",
    "        min_lr=1e-6,\n",
    "        threshold=1e-2,\n",
    "\n",
    "        dg_config=DataGenerateConfig(mean_load=50.0, var_load=10.0, iid_var=1.0, theta=0.9),\n",
    "        ar_config=ARConfig(order=5),\n",
    "        lstm_config=LSTMConfig(hidden_size=64, num_layers=4),\n",
    "        gat_config=GATConfig(hidden_size=32, num_heads=8, num_gat_layers=3),\n",
    "        gnn_config=GNNConfig(hidden_size=32, num_layers=3)\n",
    "\n",
    "    )\n",
    "\n",
    "    config.print_config_info()\n",
    "\n",
    "    if RE_GENERATE_DATA:\n",
    "        data_generate = DataGenerate(config)\n",
    "\n",
    "    data_manage = DataManage(config)\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
